# Learning Outcomes

By the end of this 13-week course, **you will personally build, run, and own** a complete state-of-the-art autonomous humanoid robot — using exactly the same tools and models that Tesla Optimus, Figure 01, 1X, and NVIDIA GR00T ship in 2025–2026.

You will be able to confidently say (and prove with working code + video demos):

### Core Robotics Mastery
- Design, model, and control a full 30+ degree-of-freedom humanoid robot from scratch using URDF/Xacro and ros2_control  
- Write production-grade ROS 2 code in both Python (rclpy) and C++ (rclcpp)  
- Orchestrate complex robotic systems with launch files, parameters, and the colcon build system  
- Implement joint trajectory controllers and understand the difference between differential-drive and bipedal locomotion

### Simulation & Digital Twin Expertise
- Simulate realistic physics, sensors (LiDAR, RGB-D, IMU), and sensor noise in Gazebo Harmonic  
- Build photorealistic environments and human-robot interactions using Unity Robotics Hub and ROS-TCP  
- Master NVIDIA Isaac Sim: USD assets, Replicator synthetic data generation, domain randomization, and faster-than-realtime physics

### Cutting-Edge Perception & Navigation
- Run hardware-accelerated visual SLAM (cuVSLAM) and real-time 3D reconstruction (nvblox) on Jetson hardware  
- Deploy Gemini foundation models for zero-shot object detection and segmentation  
- Navigate bipedal robots safely in cluttered environments using Nav2 with dynamic balancing constraints

### Vision-Language-Action (VLA) & Embodied Intelligence
- Turn natural voice commands into executable action sequences using Whisper Live → GPT-4o-realtime / Llama 3 → action parsing  
- Deploy and fine-tune open-source VLA models (Octo, RT-X, OpenVLA) that map language + vision directly to robot actions  
- Train your own VLA policies end-to-end inside Isaac Sim  
- Build fully offline, internet-free autonomous agents

### Sim-to-Real & Real Hardware Deployment
- Achieve zero-shot or few-shot sim-to-real transfer from Isaac Sim to real humanoid hardware  
- Deploy perception, planning, and control pipelines on NVIDIA Jetson Orin edge devices  
- (Optional) Run your capstone live on a real Unitree G1, Unitree Go2, or robotic arm

### Capstone Deliverable
A complete **Autonomous Humanoid Assistant** that can:
1. Hear an open-ended voice command (“Clean up the trash”, “Bring me water”, etc.)  
2. Plan and sequence the task using an LLM  
3. Walk bipedally to the goal while avoiding obstacles  
4. Build a 3D map of the environment in real time  
5. Detect and localize objects with foundation models  
6. Pick and place or manipulate objects using a trained VLA policy  
7. Verbally confirm completion

This is **not a demo** — it is a fully working, reproducible, deployable embodied agent built 100 % by you.

### Career-Level Outcome
When you finish, you will be in the top 0.1 % of engineers worldwide who can build and ship modern humanoid robots end-to-end.  
You will have a portfolio that immediately qualifies you for roles at:
- Tesla (Optimus) · Figure · 1X · Agility Robotics · Boston Dynamics · Sanctuary · Apptronik · NVIDIA Robotics · Covariant · Google DeepMind Robotics · any serious humanoid startup

You won’t just understand Physical AI.  
**You will have built it.**

Next → [Hardware Requirements](./hardware-requirements.mdx)